# Интеллектуальный помощник оператора службы поддержки

Этот проект предоставляет готовую реализацию **Retrieval-Augmented Generation** (RAG) системы, которая использует языковую модель для генерации ответов на основе поиска по базе данных (retriever). В основе системы лежат предварительно обученные модели LLM и FAISS для поиска релевантных документов.

## Установка

Перед началом работы убедитесь, что у вас установлен Python версии 3.8 и выше. Необходимые библиотеки можно установить с помощью `pip`:

```bash
pip install torch transformers langchain langchain_community faiss-cpu pandas tqdm
```

## Основные функции

### 1. **Инициализация модели**
Класс `llmmodel` предназначен для создания и управления retrieval-based архитектурой с языковой моделью. Он использует предобученные модели из библиотеки `HuggingFace`.

#### Пример инициализации:
```python
from fullrag import llmmodel

rag = llmmodel(llm_model_name="Qwen/Qwen2.5-7B-Instruct")
```

### 2. **Методы класса `llmmodel`**

#### `__init__(self, embeddings_model_name, llm_model_name, data_path, device)`
Инициализирует объект модели с загруженными базами данных и языковой моделью.

- **Параметры**:
  - `embeddings_model_name`: название модели для embeddings, по умолчанию `"deepvk/USER-bge-m3"`.
  - `llm_model_name`: название языковой модели для генерации текста.
  - `data_path`: путь к данным (базе данных).
  - `device`: устройство для вычислений (`"cuda"` для использования GPU или `"cpu"`).

#### `load_embeddings(self)`
Загружает модель embeddings для поиска.

#### `load_model(self)`
Загружает языковую модель (LLM) для генерации текста.

#### `load_database(self, path)`
Загружает базу данных (FAISS) для поиска по векторным представлениям.

- **Параметры**:
  - `path`: путь к сохранённой базе данных.

#### `load_all(self)`
Загружает все базы данных (основную базу данных, пользовательскую и базу условий).

#### `search_db(self, db: FAISS, question: str, number=5)`
Ищет по базе данных наиболее релевантные документы с помощью модели retriever.

- **Параметры**:
  - `db`: объект FAISS, представляющий базу данных для поиска.
  - `question`: строка с вопросом пользователя для поиска.
  - `number`: количество документов для возвращения.
  
- **Возвращает**: список документов.

#### `llm_question_answer(self, question: str, baza, userdata, conddata)`
Генерирует ответ на основе вопроса и контекста (из базы данных).

- **Параметры**:
  - `question`: вопрос пользователя.
  - `baza`: информация из основной базы данных.
  - `userdata`: информация из пользовательской базы данных.
  - `conddata`: информация из базы данных условий.

#### `generate_answer(self, query)`
Генерирует ответ на основе запроса пользователя, найденной информации в базе данных и контекста.

- **Параметры**:
  - `query`: строка запроса пользователя.

- **Возвращает**: строка с сгенерированным ответом.

### Пример использования

1. Инициализация модели с указанием языка и пути к данным:

```python
from fullrag import llmmodel

# Инициализируем объект RAG-модели
rag = llmmodel(llm_model_name="Qwen/Qwen2.5-7B-Instruct")
```

2. Поиск и генерация ответа на запрос:

```python
question = "Как восстановить пароль на платформе?"

# Генерация ответа на запрос
answer = rag.generate_answer(question)
print(answer)
```

### 3. **Обработка текста**
Метод `preprocess` используется для очистки входного текста от ненужных символов и ссылок.

```python
clean_text = preprocess("Пример текста с лишними символами: https://example.com!")
print(clean_text)  # Вывод: Пример текста с лишними символами
```

## Параметры и конфигурация

- **Модель LLM**: Вы можете использовать любую предобученную модель LLM из библиотеки HuggingFace, передав её название в `llm_model_name`. Например, `"Qwen/Qwen2.5-7B-Instruct"` или `"IlyaGusev/saiga_llama3_8b"`.
- **Устройство вычислений**: По умолчанию используется `"cuda"`, если у вас есть GPU. Если вы работаете на CPU, установите `device="cpu"`.

## Требования

- Python 3.8 и выше
- `torch` — для запуска языковой модели.
- `transformers` — для работы с моделями LLM и embeddings.
- `faiss-cpu` — для поиска по базе данных.
- `pandas` и `tqdm` — для работы с данными и отображения прогресса.
